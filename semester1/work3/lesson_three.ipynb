{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T15:14:59.072319Z",
     "start_time": "2024-10-09T15:14:59.067027Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d82a2d8a6d6cb1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T15:14:59.092947Z",
     "start_time": "2024-10-09T15:14:59.088354Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = \"Backgammon is one of the oldest known board games. Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East. It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "9ae712cd0404b537",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T15:14:59.111633Z",
     "start_time": "2024-10-09T15:14:59.106077Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backgammon is one of the oldest known board games.\n",
      "\n",
      "Its history can be traced back nearly 5,000 years to archeological discoveries in the Middle East.\n",
      "\n",
      "It is a two player game where each player has fifteen checkers which move between twenty-four points according to the roll of two dice.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#токенизация по предложениям\n",
    "nltk.download('punkt')\n",
    "\n",
    "sentences = nltk.sent_tokenize(text)\n",
    "for sentence in sentences:\n",
    "    print(sentence, end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee1d48aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Backgammon',\n",
       " 'is',\n",
       " 'one',\n",
       " 'of',\n",
       " 'the',\n",
       " 'oldest',\n",
       " 'known',\n",
       " 'board',\n",
       " 'games',\n",
       " '.']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "50b687429936c5d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T15:14:59.127144Z",
     "start_time": "2024-10-09T15:14:59.120761Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmer: better\n",
      "Lemmatizer: good\n",
      "\n",
      "Stemmer: drove\n",
      "Lemmatizer: drive\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Лемманизация и стемминг\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def compare_stemmer_and_lemmatizer(stemmer, lemmatizer, word, pos):\n",
    " \n",
    "    print(\"Stemmer:\", stemmer.stem(word))\n",
    "    print(\"Lemmatizer:\", lemmatizer.lemmatize(word, pos))\n",
    "    print()\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "compare_stemmer_and_lemmatizer(stemmer, lemmatizer, word = \"better\", pos = wordnet.ADJ)\n",
    "compare_stemmer_and_lemmatizer(stemmer, lemmatizer, word = \"drove\", pos = wordnet.VERB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5026f06a7f62aa19",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T15:16:14.957015Z",
     "start_time": "2024-10-09T15:16:14.937522Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    }
   ],
   "source": [
    "#стоп слова\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "print(stopwords.words(\"russian\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "53767c0580ddd92e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T15:17:50.540736Z",
     "start_time": "2024-10-09T15:17:50.525615Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['backgammon', 'one', 'oldest', 'known', 'board', 'games', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "# nltk.download()\n",
    "\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "sentence = \"Backgammon is one of the oldest known board games.\".lower()\n",
    "\n",
    "words = nltk.word_tokenize(sentence)\n",
    "without_stop_words = []\n",
    "for word in words:\n",
    "    if not(word in stopwords.words(\"english\")):\n",
    "        without_stop_words.append(word)\n",
    "\n",
    "\n",
    "print(without_stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "534beb06eb7ac102",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T15:28:22.755491Z",
     "start_time": "2024-10-09T15:28:22.749041Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The development of snowboarding was inspired by skateboarding  sledding  surfing and skiing \n",
      "The development of snowboard was inspired by skateboard, sledd, surf and ski.\n"
     ]
    }
   ],
   "source": [
    "#Регулярные выражения\n",
    "\n",
    "import re\n",
    "sentence = \"The development of snowboarding was inspired by skateboarding, sledding, surfing and skiing.\"\n",
    "pattern = r\"[^\\w]\"\n",
    "print(re.sub(pattern, \" \", sentence))\n",
    "\n",
    "pattern = r'\\b\\w+?ing\\b'\n",
    "\n",
    "result = re.sub(pattern, lambda x: x.group()[:-3], sentence)\n",
    "\n",
    "print(result)\n",
    "\n",
    "#все, кроме последовательности ing - минизадачка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "358d693033b10701",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T15:58:51.555632Z",
     "start_time": "2024-10-09T15:58:51.500120Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"I like this movie, it's funny.\", 'I hate this movie.', 'This was awesome! I like it.', 'Nice one. I love it.']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>awesome</th>\n",
       "      <th>funny</th>\n",
       "      <th>hate</th>\n",
       "      <th>it</th>\n",
       "      <th>like</th>\n",
       "      <th>love</th>\n",
       "      <th>movie</th>\n",
       "      <th>nice</th>\n",
       "      <th>one</th>\n",
       "      <th>this</th>\n",
       "      <th>was</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   awesome  funny  hate  it  like  love  movie  nice  one  this  was\n",
       "0        0      1     0   1     1     0      1     0    0     1    0\n",
       "1        0      0     1   0     0     0      1     0    0     1    0\n",
       "2        1      0     0   1     1     0      0     0    0     1    1\n",
       "3        0      0     0   1     0     1      0     1    1     0    0"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Мешок слов\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "with open(\"movie.txt\", \"r\") as file:\n",
    "    documents = file.read().splitlines()\n",
    "    \n",
    "print(documents)\n",
    "\n",
    "count_vectorizer = CountVectorizer()\n",
    "\n",
    "bag_of_words = count_vectorizer.fit_transform(documents)\n",
    "\n",
    "feature_names = count_vectorizer.get_feature_names_out()\n",
    "pd.DataFrame(bag_of_words.toarray(), columns = feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "705aab94bbe29620",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T16:37:01.216136Z",
     "start_time": "2024-10-09T16:37:01.208328Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "['<UNK>', 'England', 'London', 'a', 'and', 'c', 'capital', 'city', 'is', 'most', 'of', 'popular', 'the']\n"
     ]
    }
   ],
   "source": [
    "# Cловарь\n",
    "\n",
    "from nltk.lm import Vocabulary\n",
    "from nltk.util import ngrams\n",
    "\n",
    "words = ['London', 'a', 'is', 'the', 'capital', 'and', 'the', 'a', 'most', 'popular', 'city', 'a', 'of', 'England']\n",
    "vocab = Vocabulary(words, unk_cutoff=1)\n",
    "vocab.update([\"c\", \"c\"])  \n",
    "\n",
    "\n",
    "print( len(vocab) )                  \n",
    "print( sorted(vocab) )        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a82ca5b1a1a15a6b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('London', 'a', 'is')\n",
      "('a', 'is', 'the')\n",
      "('is', 'the', 'capital')\n",
      "('the', 'capital', 'and')\n",
      "('capital', 'and', 'the')\n",
      "('and', 'the', 'a')\n",
      "('the', 'a', 'most')\n",
      "('a', 'most', 'popular')\n",
      "('most', 'popular', 'city')\n",
      "('popular', 'city', 'a')\n",
      "('city', 'a', 'of')\n",
      "('a', 'of', 'England')\n"
     ]
    }
   ],
   "source": [
    "#N-граммы\n",
    "\n",
    "n = 3 \n",
    "trigrams = list(nltk.ngrams(words, n))\n",
    "\n",
    "for trigram in trigrams:\n",
    "   print(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "efbe3e123135ae10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-09T16:56:24.598294Z",
     "start_time": "2024-10-09T16:56:24.574155Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TF-IDF\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
